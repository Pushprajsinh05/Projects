{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-EEv9utoT69"
   },
   "outputs": [],
   "source": [
    "#MOVIE RECOMMENDATION SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-EEv9utoT69"
   },
   "outputs": [],
   "source": [
    "# Task 1: kNN-based Collaborative Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Step 1: Load and Preprocess the Data\n",
    "\n",
    "# Load the ratings dataset\n",
    "# The ratings.dat file is delimited by '::'. It contains userID, movieID, rating, and timestamp.\n",
    "ratings = pd.read_csv('ratings.dat', sep='::', names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\n",
    "\n",
    "# Drop the 'Timestamp' column as it's not necessary for recommendation calculations\n",
    "ratings.drop('Timestamp', axis=1, inplace=True)\n",
    "\n",
    "# Create a user-item matrix (rows: users, columns: movies, values: ratings)\n",
    "user_item_matrix = ratings.pivot(index='UserID', columns='MovieID', values='Rating')\n",
    "\n",
    "# Randomly select a test user from the user-item matrix\n",
    "test_user = random.choice(user_item_matrix.index)\n",
    "print(f\"Test user selected: {test_user}\")\n",
    "\n",
    "# Step 2: Define a Function to Calculate Similarity\n",
    "\n",
    "# Function to calculate similarity using either cosine or Pearson correlation\n",
    "def calculate_similarity(user_item_matrix, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        # Cosine similarity (fill NaN with 0 for the calculation)\n",
    "        similarity_matrix = cosine_similarity(user_item_matrix.fillna(0))\n",
    "    elif metric == 'pearson':\n",
    "        # Pearson correlation\n",
    "        similarity_matrix = user_item_matrix.T.corr()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown metric. Use 'cosine' or 'pearson'.\")\n",
    "    \n",
    "    # Return the similarity matrix as a DataFrame for easier indexing\n",
    "    return pd.DataFrame(similarity_matrix, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "\n",
    "# Step 3: Calculate Cosine and Pearson Similarity Matrices\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "cosine_similarity_matrix = calculate_similarity(user_item_matrix, 'cosine')\n",
    "\n",
    "# Calculate Pearson similarity matrix\n",
    "pearson_similarity_matrix = calculate_similarity(user_item_matrix, 'pearson')\n",
    "\n",
    "# Step 4: Define a Function to Predict Ratings\n",
    "\n",
    "# Function to predict the rating of a movie for a user using k-nearest neighbors\n",
    "def predict_rating(user_item_matrix, similarity_matrix, user_id, movie_id, k):\n",
    "    # Check if the movie exists in the matrix (has been rated by others)\n",
    "    if movie_id not in user_item_matrix.columns:\n",
    "        return np.nan\n",
    "    \n",
    "    # Get k most similar users who have rated the movie\n",
    "    similar_users = similarity_matrix[user_id].drop(user_id).nlargest(k)\n",
    "    ratings = user_item_matrix.loc[similar_users.index, movie_id].dropna()\n",
    "    \n",
    "    # If no similar users have rated the movie, return NaN\n",
    "    if len(ratings) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate the weighted average based on similarity\n",
    "    predicted_rating = (ratings * similar_users[ratings.index]).sum() / similar_users[ratings.index].sum()\n",
    "    return predicted_rating\n",
    "\n",
    "# Step 5: Generate Predictions for Different k Values\n",
    "\n",
    "# Define a range of k values (number of neighbors) for experimentation\n",
    "k_values = range(1, 50)\n",
    "\n",
    "# Initialize dictionaries to store predictions for both cosine and Pearson similarity\n",
    "predictions_cosine = {k: [] for k in k_values}\n",
    "predictions_pearson = {k: [] for k in k_values}\n",
    "actuals = []\n",
    "\n",
    "# Calculate predictions and store actual ratings for the test user\n",
    "for movie_id, actual_rating in user_item_matrix.loc[test_user].dropna().items():\n",
    "    actuals.append(actual_rating)\n",
    "    for k in k_values:\n",
    "        # Predict using cosine similarity\n",
    "        pred_cosine = predict_rating(user_item_matrix, cosine_similarity_matrix, test_user, movie_id, k)\n",
    "        predictions_cosine[k].append(pred_cosine)\n",
    "        \n",
    "        # Predict using Pearson correlation\n",
    "        pred_pearson = predict_rating(user_item_matrix, pearson_similarity_matrix, test_user, movie_id, k)\n",
    "        predictions_pearson[k].append(pred_pearson)\n",
    "\n",
    "# Step 6: Define a Function to Calculate RMSE\n",
    "\n",
    "# Function to calculate RMSE (Root Mean Square Error) while filtering out NaN predictions\n",
    "def calculate_rmse(predictions, actuals):\n",
    "    # Filter out NaN predictions\n",
    "    filtered_predictions = [pred for pred in predictions if not np.isnan(pred)]\n",
    "    filtered_actuals = [actual for actual, pred in zip(actuals, predictions) if not np.isnan(pred)]\n",
    "    \n",
    "    # Calculate RMSE if the lengths match and are greater than 0\n",
    "    if len(filtered_actuals) == len(filtered_predictions) and len(filtered_actuals) > 0:\n",
    "        return np.sqrt(mean_squared_error(filtered_actuals, filtered_predictions))\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Step 7: Calculate and Store RMSE Values for Different k Values\n",
    "\n",
    "# Initialize lists to store RMSE values for both cosine and Pearson\n",
    "rmse_cosine_values = []\n",
    "rmse_pearson_values = []\n",
    "\n",
    "# Calculate RMSE for each k value for both Cosine and Pearson similarity\n",
    "for k in k_values:\n",
    "    rmse_cosine = calculate_rmse(predictions_cosine[k], actuals)\n",
    "    rmse_pearson = calculate_rmse(predictions_pearson[k], actuals)\n",
    "    \n",
    "    # Store RMSE values for Cosine\n",
    "    if not np.isnan(rmse_cosine):\n",
    "        rmse_cosine_values.append((k, rmse_cosine))\n",
    "        print(f\"RMSE (Cosine) for k={k}: {rmse_cosine}\")\n",
    "    \n",
    "    # Store RMSE values for Pearson\n",
    "    if not np.isnan(rmse_pearson):\n",
    "        rmse_pearson_values.append((k, rmse_pearson))\n",
    "        print(f\"RMSE (Pearson) for k={k}: {rmse_pearson}\")\n",
    "\n",
    "# Step 8: Plot RMSE for Both Cosine and Pearson Similarity\n",
    "\n",
    "# Extract k values and corresponding RMSE values for plotting\n",
    "k_values_plot_cosine, rmse_plot_cosine = zip(*rmse_cosine_values)\n",
    "k_values_plot_pearson, rmse_plot_pearson = zip(*rmse_pearson_values)\n",
    "\n",
    "# Plot RMSE vs k for both Cosine and Pearson similarity\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values_plot_cosine, rmse_plot_cosine, marker='o', label='RMSE for Cosine Similarity')\n",
    "plt.plot(k_values_plot_pearson, rmse_plot_pearson, marker='o', label='RMSE for Pearson Correlation', linestyle='--')\n",
    "plt.title('RMSE for Different k values (Cosine vs. Pearson)')\n",
    "plt.xlabel('k (Number of Neighbors)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "k = 20\n",
    "print(f\"\\nPredicted ratings using Cosine Similarity for k={k}:\")\n",
    "for movie_id, actual_rating in user_item_matrix.loc[test_user].dropna().items():\n",
    "    pred_cosine = predict_rating(user_item_matrix, cosine_similarity_matrix, test_user, movie_id, k)\n",
    "    print(f\"Movie {movie_id}: Actual={actual_rating}, Predicted={pred_cosine}\")\n",
    "\n",
    "print(f\"\\nPredicted ratings using Pearson Correlation for k={k}:\")\n",
    "for movie_id, actual_rating in user_item_matrix.loc[test_user].dropna().items():\n",
    "    pred_pearson = predict_rating(user_item_matrix, pearson_similarity_matrix, test_user, movie_id, k)\n",
    "    print(f\"Movie {movie_id}: Actual={actual_rating}, Predicted={pred_pearson}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-i5aIqXpPbu"
   },
   "outputs": [],
   "source": [
    "# Task 2: Matrix Factorization-based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load the Data\n",
    "ratings = pd.read_csv('ratings.dat', sep='::', names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\n",
    "ratings.drop('Timestamp', axis=1, inplace=True)\n",
    "\n",
    "# Create user-item matrix (rows: users, columns: movies, values: ratings)\n",
    "user_item_matrix = ratings.pivot(index='UserID', columns='MovieID', values='Rating')\n",
    "\n",
    "# Fill NaN values with the average rating for each user\n",
    "user_item_matrix_filled = user_item_matrix.fillna(user_item_matrix.mean(axis=1))\n",
    "\n",
    "# Step 2: Randomly Select 5 Movies (Test Set)\n",
    "random.seed(42)\n",
    "test_movies = random.sample(list(user_item_matrix.columns), 5)\n",
    "print(f\"Test Movies (IDs): {test_movies}\")\n",
    "\n",
    "# Step 3: Implement SVD for Matrix Factorization\n",
    "def svd_matrix_factorization(user_item_matrix, n_components=20):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    user_factors = svd.fit_transform(user_item_matrix)\n",
    "    movie_factors = svd.components_\n",
    "\n",
    "    # Reconstructed matrix approximation\n",
    "    reconstructed_matrix = np.dot(user_factors, movie_factors)\n",
    "    return reconstructed_matrix\n",
    "\n",
    "# Step 4: Improve the SVD Model by Adding User and Item Biases\n",
    "def svd_with_bias(user_item_matrix, n_components=20):\n",
    "    global_mean = user_item_matrix.stack().mean()\n",
    "\n",
    "    # Calculate user and movie biases\n",
    "    user_biases = user_item_matrix.mean(axis=1) - global_mean\n",
    "    item_biases = user_item_matrix.mean(axis=0) - global_mean\n",
    "\n",
    "    # Subtract biases from the original matrix\n",
    "    bias_adjusted_matrix = user_item_matrix.sub(user_biases, axis=0).sub(item_biases, axis=1).fillna(0)\n",
    "\n",
    "    # Perform SVD on the bias-adjusted matrix\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    user_factors = svd.fit_transform(bias_adjusted_matrix)\n",
    "    movie_factors = svd.components_\n",
    "\n",
    "    # Reconstruct the matrix by adding the biases back\n",
    "    reconstructed_matrix = np.dot(user_factors, movie_factors)\n",
    "    reconstructed_with_bias = reconstructed_matrix + user_biases.values[:, np.newaxis] + item_biases.values\n",
    "\n",
    "    return reconstructed_with_bias\n",
    "\n",
    "# Step 5: Predict Ratings for All Users on the Selected Movies\n",
    "def predict_ratings_for_movies(reconstructed_matrix, movies, user_item_matrix):\n",
    "    # Create a DataFrame of predicted ratings for all users for the selected movies\n",
    "    predicted_ratings = pd.DataFrame(reconstructed_matrix, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "    predicted_ratings_for_movies = predicted_ratings[movies]  # Select only the test movies\n",
    "    return predicted_ratings_for_movies\n",
    "\n",
    "# Step 6: Calculate RMSE for All Users on the Test Movies\n",
    "def calculate_rmse_for_movies(user_item_matrix, reconstructed_matrix, movies):\n",
    "    actual_ratings = user_item_matrix[movies].stack().dropna()  # Actual ratings for test movies\n",
    "    predicted_ratings = pd.DataFrame(reconstructed_matrix, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "    predicted_ratings = predicted_ratings[movies].stack().reindex(actual_ratings.index)  # Align predicted ratings\n",
    "    return np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "\n",
    "# Step 7: Compare RMSE for Different Numbers of Components\n",
    "components = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "rmse_svd_list = []\n",
    "rmse_svd_bias_list = []\n",
    "\n",
    "for n in components:\n",
    "    # SVD without bias\n",
    "    reconstructed_matrix_svd = svd_matrix_factorization(user_item_matrix_filled, n_components=n)\n",
    "    rmse_svd = calculate_rmse_for_movies(user_item_matrix, reconstructed_matrix_svd, test_movies)\n",
    "    rmse_svd_list.append(rmse_svd)\n",
    "    \n",
    "    # SVD with bias\n",
    "    reconstructed_matrix_svd_bias = svd_with_bias(user_item_matrix_filled, n_components=n)\n",
    "    rmse_svd_bias = calculate_rmse_for_movies(user_item_matrix, reconstructed_matrix_svd_bias, test_movies)\n",
    "    rmse_svd_bias_list.append(rmse_svd_bias)\n",
    "    \n",
    "    # Show improvement\n",
    "    print(f\"Components: {n}, RMSE (SVD without bias): {rmse_svd}, RMSE (SVD with bias): {rmse_svd_bias}, Improvement: {rmse_svd - rmse_svd_bias}\")\n",
    "\n",
    "# Step 8: Visualize the Comparison of RMSE for Different Number of Components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(components, rmse_svd_list, marker='o', label='SVD without bias', color='blue')\n",
    "plt.plot(components, rmse_svd_bias_list, marker='o', label='SVD with bias', linestyle='--', color='green')\n",
    "plt.title('RMSE Comparison for Different Number of Components (SVD vs SVD with Bias)')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step 9: Print Predicted Ratings for All Users on Test Movies (SVD without bias and SVD with bias)\n",
    "print(\"\\nPredicted Ratings (SVD without bias) for all users on the selected test movies:\")\n",
    "predicted_ratings_svd = predict_ratings_for_movies(reconstructed_matrix_svd, test_movies, user_item_matrix)\n",
    "print(predicted_ratings_svd)\n",
    "\n",
    "print(\"\\nPredicted Ratings (SVD with bias) for all users on the selected test movies:\")\n",
    "predicted_ratings_svd_bias = predict_ratings_for_movies(reconstructed_matrix_svd_bias, test_movies, user_item_matrix)\n",
    "print(predicted_ratings_svd_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-i5aIqXpPbu"
   },
   "source": [
    "# Task 3: Ranking-based Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score, ndcg_score\n",
    "import random\n",
    "\n",
    "# Step 1: Load and Preprocess the Data\n",
    "def load_ratings_data(file_path):\n",
    "    ratings = pd.read_csv(file_path, sep='::', names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\n",
    "    ratings.drop('Timestamp', axis=1, inplace=True)\n",
    "    user_item_matrix = ratings.pivot(index='UserID', columns='MovieID', values='Rating')\n",
    "    return user_item_matrix\n",
    "\n",
    "# Step 2: Randomly Select 10 Users Who Have Rated More Than 100 Movies\n",
    "def select_test_users(user_item_matrix, num_users=10):\n",
    "\n",
    "    user_ratings_count = user_item_matrix.notna().sum(axis=1)\n",
    "\n",
    "    # Filtering users who have rated more than 100 movies\n",
    "    users_with_more_than_100_ratings = user_ratings_count[user_ratings_count > 100].index\n",
    "\n",
    "    # Randomly choosing 10 users from the filtered list\n",
    "    random_users = random.sample(list(users_with_more_than_100_ratings), 10)\n",
    "    return random_users\n",
    "\n",
    "# Load data\n",
    "file_path = 'ratings.dat'\n",
    "user_item_matrix = load_ratings_data(file_path)\n",
    "\n",
    "# Select 10 random users\n",
    "test_users = select_test_users(user_item_matrix, num_users=10)\n",
    "print(f\"Selected Test Users: {test_users}\")\n",
    "\n",
    "# Step 3: Generate Top-20 Recommendations Using KNNCF\n",
    "def get_top_n_recommendations_knn(user_item_matrix, similarity_matrix, user_id, N=20, k=10):\n",
    "    \"\"\"Generate Top-N recommendations for a user using k-Nearest Neighbors Collaborative Filtering (KNNCF).\"\"\"\n",
    "    unrated_items = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id].notna()]\n",
    "    predictions = []\n",
    "    \n",
    "    for movie_id in unrated_items.index:\n",
    "        pred = predict_rating(user_item_matrix, similarity_matrix, user_id, movie_id, k)  # Using k-nearest neighbors\n",
    "    \n",
    "        if not np.isnan(pred):\n",
    "            predictions.append((movie_id, pred))\n",
    "    \n",
    "    top_n_recommendations = sorted(predictions, key=lambda x: x[1], reverse=True)[:N]\n",
    "    return [x[0] for x in top_n_recommendations]  # Return movie IDs\n",
    "\n",
    "# Step 4: Generate Top-20 Recommendations Using IMFR (Matrix Factorization with SVD)\n",
    "def get_top_n_recommendations_imfr(reconstructed_matrix, user_id, N=20):\n",
    "    \"\"\"Generate Top-N recommendations for a user using Improved Matrix Factorization.\"\"\"\n",
    "    user_ratings = pd.Series(reconstructed_matrix[user_id-1], index=user_item_matrix.columns)\n",
    "    user_ratings_filtered = user_ratings[user_item_matrix.loc[user_id].notna()]  # Filter out already rated items\n",
    "    top_n_recommendations = user_ratings_filtered.nlargest(N).index.tolist()\n",
    "    return top_n_recommendations\n",
    "\n",
    "# Step 5: Create Relevance Vector Based on Rating Threshold\n",
    "def create_relevance_vector(user_ratings, recommendations, threshold=3):\n",
    "    relevance = []\n",
    "    for movie_id in recommendations:\n",
    "        if movie_id in user_ratings.index and not np.isnan(user_ratings[movie_id]):\n",
    "            if user_ratings[movie_id] >= threshold:  # If rating >= 3, mark it as relevant\n",
    "                relevance.append(1)\n",
    "            else:\n",
    "                relevance.append(0)\n",
    "        else:\n",
    "            relevance.append(0)  # If no rating exists, it's irrelevant\n",
    "    return relevance\n",
    "\n",
    "# Step 6: Calculate Ranking Metrics (AP and NDCG)\n",
    "def calculate_average_precision(y_true, y_pred):\n",
    "    return average_precision_score(y_true, y_pred)\n",
    "\n",
    "def calculate_ndcg(y_true, y_pred, k=20):\n",
    "    return ndcg_score([y_true], [y_pred], k=k)\n",
    "\n",
    "# Step 7: Evaluate Models for Each Test User\n",
    "def evaluate_models_for_users(user_item_matrix, test_users, cosine_similarity_matrix, reconstructed_matrix_svd_bias, N=20):\n",
    "    ap_knn_values = []\n",
    "    ndcg_knn_values = []\n",
    "    ap_imfr_values = []\n",
    "    ndcg_imfr_values = []\n",
    "\n",
    "    # Evaluate each test user\n",
    "    for user_id in test_users:\n",
    "        \n",
    "        # Generate Top-20 recommendations using KNNCF\n",
    "        top_n_knn = get_top_n_recommendations_knn(user_item_matrix, cosine_similarity_matrix, user_id, N=N)\n",
    "        \n",
    "        # Generate Top-20 recommendations using IMFR\n",
    "        top_n_imfr = get_top_n_recommendations_imfr(reconstructed_matrix_svd_bias, user_id, N=N)\n",
    "        \n",
    "        # Get the actual ratings for the Top-N recommendations\n",
    "        true_ratings_knn = user_item_matrix.loc[user_id, top_n_knn]\n",
    "        true_ratings_imfr = user_item_matrix.loc[user_id, top_n_imfr]\n",
    "        \n",
    "        # Create binary relevance vectors based on a rating threshold (e.g., 3)\n",
    "        y_true_knn = create_relevance_vector(true_ratings_knn, top_n_knn, threshold=3)\n",
    "        y_true_imfr = create_relevance_vector(true_ratings_imfr, top_n_imfr, threshold=3)\n",
    "        \n",
    "        # Calculate Average Precision\n",
    "        ap_knn = calculate_average_precision(y_true_knn, top_n_knn)\n",
    "        ap_imfr = calculate_average_precision(y_true_imfr, top_n_imfr)\n",
    "        \n",
    "        # Calculate NDCG\n",
    "        ndcg_knn = calculate_ndcg(y_true_knn, top_n_knn)\n",
    "        ndcg_imfr = calculate_ndcg(y_true_imfr, top_n_imfr)\n",
    "        \n",
    "        # Store results\n",
    "        ap_knn_values.append(ap_knn)\n",
    "        ndcg_knn_values.append(ndcg_knn)\n",
    "        ap_imfr_values.append(ap_imfr)\n",
    "        ndcg_imfr_values.append(ndcg_imfr)\n",
    "\n",
    "    return np.mean(ap_knn_values), np.mean(ndcg_knn_values), np.mean(ap_imfr_values), np.mean(ndcg_imfr_values)\n",
    "\n",
    "# Step 8: Generate Similarity Matrices and Reconstructed Matrices\n",
    "cosine_similarity_matrix = calculate_similarity(user_item_matrix, 'cosine')\n",
    "reconstructed_matrix_svd_bias = svd_with_bias(user_item_matrix, n_components=20)\n",
    "\n",
    "# Step 9: Evaluate the Recommendations for the Test Users\n",
    "ap_knn, ndcg_knn, ap_imfr, ndcg_imfr = evaluate_models_for_users(user_item_matrix, test_users, cosine_similarity_matrix, reconstructed_matrix_svd_bias)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Average Precision (KNNCF): {ap_knn}\")\n",
    "print(f\"NDCG (KNNCF): {ndcg_knn}\")\n",
    "print(f\"Average Precision (IMFR): {ap_imfr}\")\n",
    "print(f\"NDCG (IMFR): {ndcg_imfr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment1_TEMPLATE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
